source('~/.active-rstudio-document', echo=TRUE)
View(data1)
source('~/.active-rstudio-document', echo=TRUE)
data1$agecat <- cut(data1$Age, c(-Inf, 0, 18, 24, 34, 44, 54, 64, Inf))
View(data1)
summary(data1)
install.packages("doBy")
library("doBy")
siterange <- function(x){c(length(x), min(x), mean(x), max(x))}
summaryBy(Age ~ agecat, data = data1, FUN = siterange)
summaryBy(Gender + Signed_In + Impressions + Clicks ~ agecat, data = data1)
library(ggplot2)
ggplot(data1, aes(x=Impressions, fill=agecat)) + geom_histogram(binwidth = 1)
ggplot(data1, aes(x=agecat, y=Impressions, fill=agecat)) + geom_boxplot()
data1$hasimps <- cut(data1$Impressions, c(-Inf, 0, Inf))
summaryBy(Clicks ~ hasimps, data = data1, FUN = siterange)
ggplot(subset(data1, Impressions > 0), aes(x = Clicks / Impressions, colour = agecat)) + geom_density()
ggplot(subset(data1, Clicks > 0), aes(x = Clicks / Impressions, colour = agecat)) + geom_density()
ggplot(subset(data1, Clicks > 0), aes(x = agecat, y = Clicks, fill = agecat)) + geom_boxplot()
ggplot(subset(data1, Clicks > 0), aes(x = Clicks, colour = agecat)) + geom_density()
data1$scode[data1$Impressions==0] <- 'NoImps'
data1$scode[data1$Impressions>0] <- 'Imps'
data1$scode[data1$Clicks>0] <- 'Clicks'
data1$scode <- factor(data1$scode)
clen <- function(x){c(length(x))}
head(data1)
etable <- summaryBy(Impressions ~ scode + Gender + agecat, data = data1, FUN = clen)
View(etable)
source('~/Desktop/Cracking-The-DS-Interview/Doing-Data-Science-Straight-Talk-From-The-Front-Line/C2-Brooklyn-Data.R', echo=TRUE)
model1 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft), data = bk.homes)
bk.homes[which(bk.homes$gross.sqft==0),]
bk.homes <- bk.homes[which(bk.homes$gross.sqft>0 & bk.homes$land.sqft>0),]
model1 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft), data = bk.homes)
summary(model1)
plot(log(bk.homes$gross.sqft), log(bk.homes$SALE.PRICE.N))
abline(model1, col="red", lwd=2)
plot(resid(model1))
model2 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft) + log(land.sqft) + factor(neighborhood),
data = bk.homes)
View(bk.homes)
model2 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft) + log(land.sqft) + factor(NEIGHBORHOOD), ata = bk.homes)
model2 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft) +
log(land.sqft) + factor(NEIGHBORHOOD), data = bk.homes)
summary(model2)
plot(resid(model2))
model2a <- lm(log(SALE.PRICE.N) ~ 0 + log(gross.sqft) +
log(land.sqft) + factor(NEIGHBORHOOD), data = bk.homes)
summary(model2a)
plot(resid(model2a))
model3 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft) +
log(land.sqft) + factor(NEIGHBORHOOD) +
factor(building.class.category), data = bk.homes)
model3 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft) +
log(land.sqft) + factor(NEIGHBORHOOD) +
factor(BUILDING.CLASS.CATEGORY), data = bk.homes)
summary(model3)
plot(resid(model3))
model4 <- lm(log(SALE.PRICE.N) ~ log(gross.sqft) + log(land.sqft) +
factor(NEIGHBORHOOD) * factor(BUILDING.CLASS.CATEGORY), data = bk.homes)
summary(model4)
plot(resid(model4))
setwd('Desktop/Cracking-The-DS-Interview/Doing-Data-Science-Straight-Talk-From-The-Front-Line')
install.packages("geoPlot")
source('~/.active-rstudio-document', echo=TRUE)
set <- read.table(file, header = TRUE, sep = "\t", row.names = "client_id")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
split <- .65
set['rand'] <- runif(nrow(set))
train <- set[(set$rand <= split),]
test <- set[(set$rand > split),]
set$y <- set$y_buy
library(mgcv)
plotrel <- function(x, y, b, title) {
# Produce a GAM smoothed representation of the data
g <- gam(as.formula("y ~ x"), family = "binomial", data = set)
xs <- seq(min(x), max(x), length = 200)
p <- predict(g, newdata = data.frame(x = x), type = "response")
# Now get empirical estimates (and discretize if non-discrete)
if (length(unique(x)) > b) {
div <- floor(max(x) / b)
x_b <- floor(x / div) * div
c <- table(x_b, y)
}
else { c <- table(x, y) }
pact <- c[ , 2] / (c[ , 1] + c[ , 2])
cnt <- c[ , 1] + c[ , 2]
xd <- as.integer(rownames(c))
plot(xs, p, type = "l", main = title,
ylab = "P(Conversion | Ad), X", xlab = "X")
points(xd, pact, type = "p", col = "red")
rug(x + runif(length(x)))
}
library(plyr)
getmae <- function(p, y, b, title, doplot) {
# Normalize to interval [0, 1]
max_p <- max(p)
p_norm <- p / max_p
# break up to b bins and rescale
bin <- max_p * floor(p_norm * b) / b
d <- data.frame(bin, p, y)
t <- table(bin)
summ <- ddply(d, .(bin), summarise, mean_p = mean(p), mean_y = mean(y))
fin <- data.frame(bin = summ$bin, mean_p = summ$mean_p, mean_y = summ$mean_y, t)
# Get wMAE
num = 0
den = 0
for (i in c(1:nrow(fin))) {
num <- num + fin$Freq[i] * abs(fin$mean_p[i] - fin$mean_y[i])
den <- den + fin$Freq[q]
}
wmae <- num / den
if (doplot == 1) {
plot(summ$bin, summ$mean_p, type = "p",
main = paste(title, " MAE =", wmae),
col = "blue", ylab = "P(C | AD, X)",
xlab = "P(C | AD, X)")
points(summ$bin, summ$mean_y, type = "p", col = "red")
rug(p)
}
return(wmae)
}
install.packages("ROCR")
library(ROCR)
get_auc < - function(ind, y) {
pred <- prediction(ind, y)
perf <- performance(pred, 'auc', fpr.stop = 1)
auc <- as.numeric(substr(slot(perf, "y.values"), 1, 8), double)
return(auc)
}
get_auc <- function(ind, y) {
pred <- prediction(ind, y)
perf <- performance(pred, 'auc', fpr.stop = 1)
auc <- as.numeric(substr(slot(perf, "y.values"), 1, 8), double)
return(auc)
}
getxval <- function(vars, data, folds, mae_bins) {
# assign each observation to a fold
data["fold"] <- floor(runif(nrow(data)) * folds) + 1
auc <- c()
wmae <- c()
fold <- c()
# make a formula object
f = as.formula(paste("Y", "~", paste(vars, collapse = "+")))
for (i in c(1:folds)) {
train <- data[(data$fold != i), ]
test <- data[(data$fold == i), ]
mod_x <- glm(f, data = train, family = binomial(logit))
p <- predict(mod_x, newdata = test, type = "response")
# Get wMAE
wmae <- c(wmae, getmae(p, test$Y, mae_bins, "dummy", 0))
fold <- c(fold, i)
auc <- c(auc, get_auc(p, test$Y))
}
return(data.frame(fold, wmae, auc))
}
View(set)
View(set)
vlist <- c("AT_BUY_BOOLEAN", "AT_FREQ_BUY", "AT_FREQ_LAST24_BUY", "AT_FREQ_LAST24_SV",
"AT_FREQ_SV", "EXPECTED_TIME_BUY", "EXPECTED_TIME_SV", "LAST_BUY",
"LAST_SV", "num_checkins")
f = as.formula(paste("Y_BUY", "~", paste(vlist, collapse = "+")))
fit <- glm(f, data = train, family = binomial(logit))
f = as.formula(paste("y_buy", "~", paste(vlist, collapse = "+")))
fit <- glm(f, data = train, family = binomial(logit))
View(set)
vlist <- c("at_buy_boolean", "at_freq_buy", "at_freq_last24_buy", "at_freq_last24_sv",
"at_freq_sv", "expected_time_buy", "expected_time_sv", "last_buy",
"last_sv", "num_checkins")
f = as.formula(paste("y_buy", "~", paste(vlist, collapse = "+")))
fit <- glm(f, data = train, family = binomial(logit))
summary(fit)
auc_mu <- c()
auc_sig <- c()
mae_mu <- c()
mae_sig <- c()
for (i in c(1:length(vlist))) {
a <- getxval(c(vlist[i]), set, 10, 100)
auc_mu <- c(auc_mu, mean(a$auc))
auc_sig <- c(auc_sig, sd(a$auc))
mae_mu <- c(mae_mu, mean(a$wmae))
mae_mu <- c(mae_sig, sd(a$wmae))
}
getxval <- function(vars, data, folds, mae_bins) {
# assign each observation to a fold
data["fold"] <- floor(runif(nrow(data)) * folds) + 1
auc <- c()
wmae <- c()
fold <- c()
# make a formula object
f = as.formula(paste("y", "~", paste(vars, collapse = "+")))
for (i in c(1:folds)) {
train <- data[(data$fold != i), ]
test <- data[(data$fold == i), ]
mod_x <- glm(f, data = train, family = binomial(logit))
p <- predict(mod_x, newdata = test, type = "response")
# Get wMAE
wmae <- c(wmae, getmae(p, test$Y, mae_bins, "dummy", 0))
fold <- c(fold, i)
auc <- c(auc, get_auc(p, test$Y))
}
return(data.frame(fold, wmae, auc))
}
for (i in c(1:length(vlist))) {
a <- getxval(c(vlist[i]), set, 10, 100)
auc_mu <- c(auc_mu, mean(a$auc))
auc_sig <- c(auc_sig, sd(a$auc))
mae_mu <- c(mae_mu, mean(a$wmae))
mae_mu <- c(mae_sig, sd(a$wmae))
}
for (i in c(1:length(vlist))) {
a <- getxval(c(vlist[i]), set, 10, 100)
auc_mu <- c(auc_mu, mean(a$auc))
auc_sig <- c(auc_sig, sd(a$auc))
mae_mu <- c(mae_mu, mean(a$wmae))
mae_mu <- c(mae_sig, sd(a$wmae))
}
